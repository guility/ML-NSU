{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libs and turning off warnings\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30,)\n"
     ]
    }
   ],
   "source": [
    "# Loading dataset\n",
    "X, y = load_breast_cancer(return_X_y=True)\n",
    "# Checking shape, looks like 1x30 pixels image\n",
    "print(X[0].shape)\n",
    "for i,every in enumerate(y):\n",
    "    if every==0:\n",
    "        y[i]=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decided to see how it looks like, would use MPL\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing testing stuff and sklearn implementation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 389 ms, sys: 223 Âµs, total: 389 ms\n",
      "Wall time: 388 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Testing runtime on n_runs.\n",
    "# As far as logregression in sklearn depends on random - running multiple times\n",
    "\n",
    "n_runs=10\n",
    "summ = float(0.0)\n",
    "for i in range(n_runs):\n",
    "    logreg_itc = LogisticRegression()\n",
    "    inter = cross_val_score(logreg_itc, X, y, cv=5)\n",
    "    summ+=np.mean(inter)\n",
    "summ = summ/float(n_runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sklearn Logistic Regression accuracy: 0.9526741054251635\n"
     ]
    }
   ],
   "source": [
    "# Mean accuracy of sklearn on that task\n",
    "print('Sklearn Logistic Regression accuracy:',summ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing my own class, inherited from BaseEstimator and ClassifierMixin\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.metrics import euclidean_distances\n",
    "\n",
    "\n",
    "class LogReg_SGD(BaseEstimator, ClassifierMixin):\n",
    "\n",
    "    def __init__(self, learning_rate=0.00000000085, n_iter=100, init='zeros'):\n",
    "        # init - 'zeros', 'ones' and 'random' - default\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_iter = n_iter\n",
    "        self.init = init\n",
    "\n",
    "        \n",
    "    # Gradient Descent optimization method.\n",
    "    def SGD(self):\n",
    "        N = len(self.y_)\n",
    "        for i in range(self.n_iter):\n",
    "            error = self.y_ - np.dot(self.X_, self.bias)\n",
    "            cost = np.dot(error.transpose(), error) / N\n",
    "            #if i % int(self.n_iter*0.1) == 0:\n",
    "            #    print('Iteration {} | Cost is {}'.format(i, cost))\n",
    "            gradient = - 2 * np.dot(self.X_.transpose(), error)\n",
    "            self.bias -= self.learning_rate * gradient\n",
    "        return self.bias\n",
    "    \n",
    "    \n",
    "    def fit(self, X, y):\n",
    "    # Check that X and y have correct shape\n",
    "        X, y = check_X_y(X, y)\n",
    "        # Store the classes seen during fit\n",
    "        self.classes_ = unique_labels(y)\n",
    "\n",
    "        self.X_ = X\n",
    "        self.y_ = y\n",
    "        # Initialization of weights.\n",
    "        # Here sklearn depends on random in some way\n",
    "        # I would try several inits: zeros, ones, random and heuristics. Maybe heuristics.\n",
    "        # Just for fun tried minus ones as well x)\n",
    "        if self.init=='zeros':\n",
    "            self.bias = np.zeros(len(X[0]))\n",
    "        if self.init=='ones':\n",
    "            self.bias = np.ones(len(X[0]))\n",
    "        if self.init=='mones':\n",
    "            self.bias = np.empty(len(X[0]))\n",
    "            self.bias.fill(-1)\n",
    "        if self.init=='random':\n",
    "            self.bias = np.random.rand(len(X[0]))\n",
    "        \n",
    "        # Learning process is all about gradient descent in that way.\n",
    "        # All parameters being transported via self object.\n",
    "        self.bias = self.SGD()\n",
    "        \n",
    "        # Return the classifier\n",
    "        return self\n",
    "\n",
    "    \n",
    "    # Function: R->[0,1)\n",
    "    # Leads from distance to \"probability\" for sample to be in 1 class.\n",
    "    def sigmoid(self, z): return 1.0 / (1 + np.exp(-z))\n",
    "    \n",
    "    def predict_prob(self, X):\n",
    "    # Check is fit had been called\n",
    "        check_is_fitted(self, ['X_', 'y_'])\n",
    "    # Input validation\n",
    "        X = check_array(X)\n",
    "\n",
    "        prediction = np.dot(X, self.bias)\n",
    "        for i,every in enumerate(prediction):\n",
    "            prediction[i] = self.sigmoid(every)\n",
    "        return prediction\n",
    "    \n",
    "    \n",
    "    def predict(self, X):\n",
    "        pred = []\n",
    "        prob = self.predict_prob(X)\n",
    "        for every in prob:\n",
    "            if every>=0.5:\n",
    "                pred.append(1)\n",
    "            else:\n",
    "                pred.append(-1)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# External stuff for testing below\n",
    "def SGD(X, y, bias, learning_rate, num_iter):\n",
    "    N = len(y)\n",
    "    for i in range(num_iter):\n",
    "        error = y - np.dot(X, bias)\n",
    "        cost = np.dot(error.transpose(), error) / N\n",
    "        if i % int(num_iter/10) == 0:\n",
    "            print('Iteration {} | Cost is {}'.format(i, cost))\n",
    "        gradient = - 2 * np.dot(X.transpose(), error)\n",
    "        bias -= learning_rate * gradient\n",
    "    return bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 | Cost is 1.0\n",
      "Iteration 100 | Cost is 0.7381425569916857\n",
      "Iteration 200 | Cost is 0.6791947283745655\n",
      "Iteration 300 | Cost is 0.6483280099116778\n",
      "Iteration 400 | Cost is 0.6257091188818952\n",
      "Iteration 500 | Cost is 0.6078836132728872\n",
      "Iteration 600 | Cost is 0.5936068645821517\n",
      "Iteration 700 | Cost is 0.5820874295385967\n",
      "Iteration 800 | Cost is 0.572732945231407\n",
      "Iteration 900 | Cost is 0.5650863746531258\n"
     ]
    }
   ],
   "source": [
    "# Used to test how big should LR be.\n",
    "# Found smthg like optimal at 0.000000000857, with number of iterations about 100.\n",
    "# Bigger causes Nan in answer\n",
    "weights = SGD(X,y,np.zeros(30),learning_rate=0.000000000857, num_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing efficiency of different initialization methods:\n",
    "init_ones = LogReg_SGD(init='ones')\n",
    "init_mones = LogReg_SGD(init='mones')\n",
    "init_zeros = LogReg_SGD(init='zeros')\n",
    "init_random = LogReg_SGD(init='random')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization with ones accuracy: 0.8035552135436708\n",
      "Initialization with random accuracy: 0.9085186610234708\n",
      "Initialization with zeros accuracy: 0.9085186610234708\n",
      "CPU times: user 1.51 s, sys: 1.71 s, total: 3.22 s\n",
      "Wall time: 810 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Running 10 times to exclude influence of randomness\n",
    "n_runs=10\n",
    "summ_0 = float(0.0)\n",
    "summ_1 = float(0.0)\n",
    "summ_r = float(0.0)\n",
    "\n",
    "for i in range(n_runs):\n",
    "    res_0 = cross_val_score(init_zeros, X, y, cv=5)\n",
    "    summ_0+=np.mean(res_0)\n",
    "    \n",
    "    res_1 = cross_val_score(init_ones, X, y, cv=5)\n",
    "    summ_1+=np.mean(res_1)\n",
    "    \n",
    "    res_r = cross_val_score(init_random, X, y, cv=5)\n",
    "    summ_r+=np.mean(res_0)\n",
    "    \n",
    "summ_0 = summ_0/float(n_runs)\n",
    "summ_1 = summ_1/float(n_runs)\n",
    "summ_r = summ_r/float(n_runs)\n",
    "\n",
    "print(\"Initialization with ones accuracy:\", summ_1)\n",
    "print(\"Initialization with random accuracy:\", summ_r)\n",
    "print(\"Initialization with zeros accuracy:\", summ_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Cost function is much better in current case for zero-init method.<br>\n",
    "> So I would compare it with sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of my implementation: 0.9085186610234708\n",
      "Accuracy of Sklearn implem.: 0.9526741054251635\n",
      "Difference: 0.04415544440169272\n",
      "Number of errors in my LR: ~10\n",
      "Number of errors in sklearn: ~5\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of my implementation:\", summ_0)\n",
    "print(\"Accuracy of Sklearn implem.:\", summ)\n",
    "print(\"Difference:\", summ-summ_0)\n",
    "print(\"Number of errors in my LR: ~\"+str(int((1-summ_0)*len(y)*0.2)))\n",
    "print(\"Number of errors in sklearn: ~\"+str(int((1-summ)*len(y)*0.2)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
